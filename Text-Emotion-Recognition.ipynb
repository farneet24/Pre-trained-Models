{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly as px\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-29T18:27:47.154129Z","iopub.execute_input":"2023-08-29T18:27:47.154691Z","iopub.status.idle":"2023-08-29T18:27:47.173035Z","shell.execute_reply.started":"2023-08-29T18:27:47.154652Z","shell.execute_reply":"2023-08-29T18:27:47.172118Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Processing Training Data","metadata":{}},{"cell_type":"code","source":"# Set the file path for the training dataset\nfile_path = \"/kaggle/input/emotions-dataset-for-nlp/train.txt\"\n\n# Initialize an empty list to hold the data\ndata = []\n\n# Open the file in read mode and populate the data list\nwith open(file_path, 'r') as file:\n    # Loop through each line in the file\n    for line in file:\n        # Strip leading/trailing whitespaces and split by ';'\n        values = line.strip().split(';')\n        \n        # Append the parsed values to the data list\n        data.append(values)\n\n# Convert the list of data into a Pandas DataFrame\n# Columns are named 'text' and 'emotion'\ntrain_df = pd.DataFrame(data, columns=['text', 'emotion'])\n\n# Display the DataFrame\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-08-29T18:31:38.103329Z","iopub.execute_input":"2023-08-29T18:31:38.104201Z","iopub.status.idle":"2023-08-29T18:31:38.148165Z","shell.execute_reply.started":"2023-08-29T18:31:38.104155Z","shell.execute_reply":"2023-08-29T18:31:38.146867Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                    text  emotion\n0                                i didnt feel humiliated  sadness\n1      i can go from feeling so hopeless to so damned...  sadness\n2       im grabbing a minute to post i feel greedy wrong    anger\n3      i am ever feeling nostalgic about the fireplac...     love\n4                                   i am feeling grouchy    anger\n...                                                  ...      ...\n15995  i just had a very brief time in the beanbag an...  sadness\n15996  i am now turning and i feel pathetic that i am...  sadness\n15997                     i feel strong and good overall      joy\n15998  i feel like this was such a rude comment and i...    anger\n15999  i know a lot but i feel so stupid because i ca...  sadness\n\n[16000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15995</th>\n      <td>i just had a very brief time in the beanbag an...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>15996</th>\n      <td>i am now turning and i feel pathetic that i am...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>15997</th>\n      <td>i feel strong and good overall</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>15998</th>\n      <td>i feel like this was such a rude comment and i...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>15999</th>\n      <td>i know a lot but i feel so stupid because i ca...</td>\n      <td>sadness</td>\n    </tr>\n  </tbody>\n</table>\n<p>16000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop duplicate rows from the training DataFrame\ntrain_df = train_df.drop_duplicates()\n\n# Drop rows with NaN (missing) values from the training DataFrame\ntrain_df = train_df.dropna()\n\n# Reset the index after dropping rows\ntrain_df = train_df.reset_index(drop=True)\n# Count the occurrences of different emotions in the training data\ntrain_df['emotion'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:49:04.657379Z","iopub.execute_input":"2023-08-19T09:49:04.659721Z","iopub.status.idle":"2023-08-19T09:49:04.714558Z","shell.execute_reply.started":"2023-08-19T09:49:04.659685Z","shell.execute_reply":"2023-08-19T09:49:04.702869Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"joy         5362\nsadness     4666\nanger       2159\nfear        1937\nlove        1304\nsurprise     572\nName: emotion, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Processing Valid Data","metadata":{}},{"cell_type":"code","source":"# Define the path for the validation dataset located in Kaggle's directory\nfile_path = \"/kaggle/input/emotions-dataset-for-nlp/val.txt\"\n\n# Initialize an empty list to temporarily hold our parsed data\ndata = []\n\n# Open the validation file for reading\nwith open(file_path, 'r') as file:\n    # Loop through each line in the validation dataset file\n    for line in file:\n        # Clean up the line and split it using ';' as a delimiter\n        values = line.strip().split(';')\n        \n        # Add the parsed line (text and emotion) to our data list\n        data.append(values)\n\n# Convert the list into a DataFrame for easier manipulation later\n# I'm setting the column names to 'text' and 'emotion' for clarity\nvalid_df = pd.DataFrame(data, columns=['text', 'emotion'])\n\n# Display the DataFrame\nvalid_df","metadata":{"execution":{"iopub.status.busy":"2023-08-29T18:32:27.814013Z","iopub.execute_input":"2023-08-29T18:32:27.814367Z","iopub.status.idle":"2023-08-29T18:32:27.837942Z","shell.execute_reply.started":"2023-08-29T18:32:27.814337Z","shell.execute_reply":"2023-08-29T18:32:27.836798Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                   text  emotion\n0     im feeling quite sad and sorry for myself but ...  sadness\n1     i feel like i am still looking at a blank canv...  sadness\n2                        i feel like a faithful servant     love\n3                     i am just feeling cranky and blue    anger\n4     i can have for a treat or if i am feeling festive      joy\n...                                                 ...      ...\n1995  im having ssa examination tomorrow in the morn...  sadness\n1996  i constantly worry about their fight against n...      joy\n1997  i feel its important to share this info for th...      joy\n1998  i truly feel that if you are passionate enough...      joy\n1999  i feel like i just wanna buy any cute make up ...      joy\n\n[2000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>im feeling quite sad and sorry for myself but ...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i feel like i am still looking at a blank canv...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i feel like a faithful servant</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am just feeling cranky and blue</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i can have for a treat or if i am feeling festive</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>im having ssa examination tomorrow in the morn...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>i constantly worry about their fight against n...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>i feel its important to share this info for th...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>i truly feel that if you are passionate enough...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>i feel like i just wanna buy any cute make up ...</td>\n      <td>joy</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop duplicate rows from the training DataFrame\nvalid_df = valid_df.drop_duplicates()\n\n# Drop rows with NaN (missing) values from the training DataFrame\nvalid_df = valid_df.dropna()\n\n# Reset the index after dropping rows\nvalid_df = valid_df.reset_index(drop=True)\n# Count the occurrences of different emotions in the training data\nvalid_df['emotion'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-29T18:45:15.503746Z","iopub.execute_input":"2023-08-29T18:45:15.504201Z","iopub.status.idle":"2023-08-29T18:45:15.538421Z","shell.execute_reply.started":"2023-08-29T18:45:15.504166Z","shell.execute_reply":"2023-08-29T18:45:15.537559Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"joy         704\nsadness     550\nanger       275\nfear        212\nlove        178\nsurprise     81\nName: emotion, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Processing Test Data","metadata":{}},{"cell_type":"code","source":"# Specify the file path for the test dataset from Kaggle's directory\nfile_path = \"/kaggle/input/emotions-dataset-for-nlp/test.txt\"\n\n# Create an empty list to collect the parsed lines from the test dataset\ndata = []\n\n# Open the test dataset file in read mode\nwith open(file_path, 'r') as file:\n    # Loop through each line in the file\n    for line in file:\n        # Remove any leading/trailing whitespaces and split by ';'\n        values = line.strip().split(';')\n        \n        # Add the cleaned-up line to the data list\n        data.append(values)\n\n# Turn the list into a DataFrame for easier data manipulation\n# Setting column names to 'text' and 'emotion' for clarity\ntest_df = pd.DataFrame(data, columns=['text', 'emotion'])\n\n# Output the DataFrame\ntest_df","metadata":{"execution":{"iopub.status.busy":"2023-08-29T18:33:10.823859Z","iopub.execute_input":"2023-08-29T18:33:10.824222Z","iopub.status.idle":"2023-08-29T18:33:10.846761Z","shell.execute_reply.started":"2023-08-29T18:33:10.824193Z","shell.execute_reply":"2023-08-29T18:33:10.844883Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                   text  emotion\n0     im feeling rather rotten so im not very ambiti...  sadness\n1             im updating my blog because i feel shitty  sadness\n2     i never make her separate from me because i do...  sadness\n3     i left with my bouquet of red and yellow tulip...      joy\n4       i was feeling a little vain when i did this one  sadness\n...                                                 ...      ...\n1995  i just keep feeling like someone is being unki...    anger\n1996  im feeling a little cranky negative after this...    anger\n1997  i feel that i am useful to my people and that ...      joy\n1998  im feeling more comfortable with derby i feel ...      joy\n1999  i feel all weird when i have to meet w people ...     fear\n\n[2000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>im feeling rather rotten so im not very ambiti...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>im updating my blog because i feel shitty</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i never make her separate from me because i do...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i left with my bouquet of red and yellow tulip...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i was feeling a little vain when i did this one</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>i just keep feeling like someone is being unki...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>im feeling a little cranky negative after this...</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>i feel that i am useful to my people and that ...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>im feeling more comfortable with derby i feel ...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>i feel all weird when i have to meet w people ...</td>\n      <td>fear</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop duplicate rows from the training DataFrame\ntest_df = test_df.drop_duplicates()\n\n# Drop rows with NaN (missing) values from the training DataFrame\ntest_df = test_df.dropna()\n\n# Reset the index after dropping rows\ntest_df = test_df.reset_index(drop=True)\n# Count the occurrences of different emotions in the training data\ntest_df['emotion'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-29T18:45:50.455078Z","iopub.execute_input":"2023-08-29T18:45:50.455479Z","iopub.status.idle":"2023-08-29T18:45:50.471736Z","shell.execute_reply.started":"2023-08-29T18:45:50.455445Z","shell.execute_reply":"2023-08-29T18:45:50.470564Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"joy         695\nsadness     581\nanger       275\nfear        224\nlove        159\nsurprise     66\nName: emotion, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Encoding the Labels","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize the label encoder\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the labels\nencoded_labels_train = label_encoder.fit_transform(train_df['emotion'])\n\n# Save the mapping between original labels and encoded labels\nlabel_mapping = {original_label: int_label for original_label, int_label in zip(train_df['emotion'], encoded_labels_train)}\nlabel_mapping","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:49:04.933261Z","iopub.execute_input":"2023-08-19T09:49:04.933965Z","iopub.status.idle":"2023-08-19T09:49:06.174208Z","shell.execute_reply.started":"2023-08-19T09:49:04.933930Z","shell.execute_reply":"2023-08-19T09:49:06.172875Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'sadness': 4, 'anger': 0, 'love': 3, 'surprise': 5, 'fear': 1, 'joy': 2}"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize the label encoder\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the labels\nencoded_labels_valid = label_encoder.fit_transform(valid_df['emotion'])\n\n# Save the mapping between original labels and encoded labels\nlabel_mapping = {original_label: int_label for original_label, int_label in zip(valid_df['emotion'], encoded_labels_valid)}\nlabel_mapping","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:49:06.177547Z","iopub.execute_input":"2023-08-19T09:49:06.178622Z","iopub.status.idle":"2023-08-19T09:49:06.192639Z","shell.execute_reply.started":"2023-08-19T09:49:06.178586Z","shell.execute_reply":"2023-08-19T09:49:06.191352Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'sadness': 4, 'love': 3, 'anger': 0, 'joy': 2, 'fear': 1, 'surprise': 5}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Importing the Pre-trained Model (Roberta)","metadata":{}},{"cell_type":"code","source":"# Import the necessary classes from the transformers library\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\n\n# Initialize a tokenizer using the 'roberta-base' pre-trained model\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Initialize a model for sequence classification using the 'roberta-base' pre-trained weights\n# Set the number of labels to 6 (according to our dataset)\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=6)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T18:29:28.900238Z","iopub.execute_input":"2023-08-29T18:29:28.900629Z","iopub.status.idle":"2023-08-29T18:29:49.359955Z","shell.execute_reply.started":"2023-08-29T18:29:28.900596Z","shell.execute_reply":"2023-08-29T18:29:49.358799Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14746134142f453f940c035573fe9404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bf392575adf470fb27f434b35327a95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e28830405eb460ca9026979cdf0be71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c98e11d38bab4d818402a381bce378fc"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import necessary classes from PyTorch and Hugging Face transformers library\nfrom torch.utils.data import Dataset, DataLoader\n\n# Define a custom Dataset class for the emotion classification task\nclass EmotionDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        # Get text and label for the given index\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        # Tokenize and encode the text using the provided tokenizer\n        encoding = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n        \n        # Return a dictionary containing tokenized data and label\n        return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Initializing variables using training and validation data\ntrain_texts, train_labels = train_df['text'], encoded_labels_train\nval_texts, val_labels = valid_df['text'], encoded_labels_valid\n\n# Create EmotionDataset instances for training and validation data\ntrain_data = EmotionDataset(train_texts, train_labels, tokenizer, max_len=128)\nval_data = EmotionDataset(val_texts, val_labels, tokenizer, max_len=128)\n\n# Create DataLoader instances for training and validation data\n# DataLoader helps manage batches and shuffling of data\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T18:30:10.006857Z","iopub.execute_input":"2023-08-29T18:30:10.007230Z","iopub.status.idle":"2023-08-29T18:30:10.018038Z","shell.execute_reply.started":"2023-08-29T18:30:10.007201Z","shell.execute_reply":"2023-08-29T18:30:10.016881Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Import the AdamW optimizer class from the transformers library\nfrom transformers import AdamW\n\n# Initialize the AdamW optimizer with the parameters of the model\n# Set the learning rate (lr) to 1e-5\noptimizer = AdamW(model.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:49:24.985425Z","iopub.execute_input":"2023-08-19T09:49:24.987071Z","iopub.status.idle":"2023-08-19T09:49:25.011032Z","shell.execute_reply.started":"2023-08-19T09:49:24.987036Z","shell.execute_reply":"2023-08-19T09:49:25.010148Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Fine Tuning the Model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import accuracy_score\n\n# Check if CUDA (GPU) is available, and move the model to the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training loop\nfor epoch in range(5):\n    model.train()  # Set the model to training mode\n    for batch in train_loader:\n        optimizer.zero_grad()  # Clear gradients\n        input_ids = batch['input_ids'].to(device)  # Move input to the device\n        attention_mask = batch['attention_mask'].to(device)  # Move attention mask to the device\n        labels = batch['labels'].to(device)  # Move labels to the device\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)  # Forward pass\n        loss = outputs[0]  # Get the loss\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update model parameters using gradients\n\n    # Validation loop\n    model.eval()  # Set the model to evaluation mode\n    val_loss = 0\n    val_accuracy = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs[0]\n            val_loss += loss.item()\n\n            # Calculate accuracy\n            logits = outputs.logits\n            predictions = torch.argmax(logits, dim=1)\n            accuracy = accuracy_score(labels.cpu(), predictions.cpu())\n            val_accuracy += accuracy\n\n    val_loss /= len(val_loader)  # Calculate average validation loss\n    val_accuracy /= len(val_loader)  # Calculate average validation accuracy\n    print(f'Validation Loss: {val_loss}')\n    print(f'Validation Accuracy: {val_accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:49:25.012432Z","iopub.execute_input":"2023-08-19T09:49:25.012743Z","iopub.status.idle":"2023-08-19T10:16:04.730581Z","shell.execute_reply.started":"2023-08-19T09:49:25.012713Z","shell.execute_reply":"2023-08-19T10:16:04.729008Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Validation Loss: 0.24647469664849933\nValidation Accuracy: 0.9057539682539683\nValidation Loss: 0.16709393162339453\nValidation Accuracy: 0.9290674603174603\nValidation Loss: 0.15009885878553467\nValidation Accuracy: 0.9325396825396826\nValidation Loss: 0.15384577797164048\nValidation Accuracy: 0.935515873015873\nValidation Loss: 0.13322170908075004\nValidation Accuracy: 0.939484126984127\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing the Model","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Transform the labels of the test data using the label encoder\ntest_enc_labels = label_encoder.transform(test_df['emotion'])\n\n# Create a test dataset using the EmotionDataset class\ntest_dataset = EmotionDataset(test_df['text'], test_enc_labels, tokenizer, max_len=128)\n\n# Create a DataLoader for the test dataset\n# DataLoader helps manage batches and shuffling of data during testing\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:16:04.735600Z","iopub.execute_input":"2023-08-19T10:16:04.738441Z","iopub.status.idle":"2023-08-19T10:16:04.750791Z","shell.execute_reply.started":"2023-08-19T10:16:04.738399Z","shell.execute_reply":"2023-08-19T10:16:04.749044Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\n\n# Lists to store predicted and true labels\nall_predictions = []\nall_true_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Perform forward pass\n        outputs = model(input_ids, attention_mask=attention_mask)\n        predictions = torch.argmax(outputs.logits, dim=1)\n\n        # Extend the lists with predicted and true labels\n        all_predictions.extend(predictions.cpu().numpy())\n        all_true_labels.extend(labels.cpu().numpy())\n\n# Convert encoded predictions back to original labels using the label encoder\npredicted_labels = label_encoder.inverse_transform(all_predictions)\ntrue_labels = label_encoder.inverse_transform(all_true_labels)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:16:04.756895Z","iopub.execute_input":"2023-08-19T10:16:04.757725Z","iopub.status.idle":"2023-08-19T10:16:18.380008Z","shell.execute_reply.started":"2023-08-19T10:16:04.757684Z","shell.execute_reply":"2023-08-19T10:16:18.378993Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Calculate accuracy using true_labels and predicted_labels\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f'Accuracy: {accuracy}')\n\n# Generate a classification report using true_labels and predicted_labels\nreport = classification_report(true_labels, predicted_labels)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:16:18.381642Z","iopub.execute_input":"2023-08-19T10:16:18.382016Z","iopub.status.idle":"2023-08-19T10:16:18.488936Z","shell.execute_reply.started":"2023-08-19T10:16:18.381982Z","shell.execute_reply":"2023-08-19T10:16:18.487951Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Accuracy: 0.928\n              precision    recall  f1-score   support\n\n       anger       0.92      0.95      0.93       275\n        fear       0.86      0.89      0.88       224\n         joy       0.95      0.95      0.95       695\n        love       0.84      0.88      0.86       159\n     sadness       0.97      0.95      0.96       581\n    surprise       0.77      0.61      0.68        66\n\n    accuracy                           0.93      2000\n   macro avg       0.88      0.87      0.88      2000\nweighted avg       0.93      0.93      0.93      2000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loop through the first 10 samples in the test data along with their true and predicted labels\nfor text, true_label, predicted_label in zip(test_df['text'][:10], true_labels[:10], predicted_labels[:10]):\n    print(f'Text: {text}')\n    print(f'True Label: {true_label}')\n    print(f'Predicted Label: {predicted_label}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:16:18.490369Z","iopub.execute_input":"2023-08-19T10:16:18.490700Z","iopub.status.idle":"2023-08-19T10:16:18.498303Z","shell.execute_reply.started":"2023-08-19T10:16:18.490669Z","shell.execute_reply":"2023-08-19T10:16:18.497108Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Text: im feeling rather rotten so im not very ambitious right now\nTrue Label: sadness\nPredicted Label: sadness\n\nText: im updating my blog because i feel shitty\nTrue Label: sadness\nPredicted Label: sadness\n\nText: i never make her separate from me because i don t ever want her to feel like i m ashamed with her\nTrue Label: sadness\nPredicted Label: sadness\n\nText: i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\nTrue Label: joy\nPredicted Label: joy\n\nText: i was feeling a little vain when i did this one\nTrue Label: sadness\nPredicted Label: sadness\n\nText: i cant walk into a shop anywhere where i do not feel uncomfortable\nTrue Label: fear\nPredicted Label: fear\n\nText: i felt anger when at the end of a telephone call\nTrue Label: anger\nPredicted Label: anger\n\nText: i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\nTrue Label: joy\nPredicted Label: joy\n\nText: i like to have the same breathless feeling as a reader eager to see what will happen next\nTrue Label: joy\nPredicted Label: joy\n\nText: i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\nTrue Label: anger\nPredicted Label: anger\n\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, 'emotion_model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:22:33.551731Z","iopub.execute_input":"2023-08-19T10:22:33.552104Z","iopub.status.idle":"2023-08-19T10:22:34.508431Z","shell.execute_reply.started":"2023-08-19T10:22:33.552077Z","shell.execute_reply":"2023-08-19T10:22:34.507305Z"},"trusted":true},"execution_count":27,"outputs":[]}]}
