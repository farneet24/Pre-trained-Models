{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Importing Necessary Libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T19:45:32.601163Z","iopub.status.busy":"2023-08-29T19:45:32.600763Z","iopub.status.idle":"2023-08-29T19:45:32.606533Z","shell.execute_reply":"2023-08-29T19:45:32.605156Z","shell.execute_reply.started":"2023-08-29T19:45:32.601130Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"markdown","metadata":{},"source":["# Importing Data for Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset from the specified path\n","path = \"/kaggle/input/twitter-and-reddit-sentimental-analysis-dataset/Twitter_Data.csv\"\n","data = pd.read_csv(path)\n","\n","# Drop rows with missing values (NaN) from the dataset\n","data.dropna(inplace=True)\n","\n","# Drop duplicate rows based on the 'clean_text' column\n","data.drop_duplicates(subset=['clean_text'], inplace=True)\n","\n","# Extract texts and labels from the cleaned dataset\n","texts = data['clean_text'].values\n","labels = data['category'].values  \n","\n","# Split data into training and validation sets\n","train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["## Encoding the labels"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T06:39:42.851509Z","iopub.status.busy":"2023-08-23T06:39:42.851027Z","iopub.status.idle":"2023-08-23T06:39:42.922535Z","shell.execute_reply":"2023-08-23T06:39:42.920924Z","shell.execute_reply.started":"2023-08-23T06:39:42.851464Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{1.0: 2, 0.0: 1, -1.0: 0}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Initialize the label encoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the labels\n","encoded_labels_train = label_encoder.fit_transform(train_labels)\n","\n","# Save the mapping between original labels and encoded labels\n","label_mapping = {original_label: int_label for original_label, int_label in zip(train_labels, encoded_labels_train)}\n","label_mapping"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T06:39:44.315102Z","iopub.status.busy":"2023-08-23T06:39:44.314630Z","iopub.status.idle":"2023-08-23T06:39:44.357384Z","shell.execute_reply":"2023-08-23T06:39:44.355567Z","shell.execute_reply.started":"2023-08-23T06:39:44.315059Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{0.0: 1, 1.0: 2, -1.0: 0}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Initialize the label encoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the labels\n","encoded_labels_valid = label_encoder.fit_transform(val_labels)\n","\n","# Save the mapping between original labels and encoded labels\n","label_mapping = {original_label: int_label for original_label, int_label in zip(val_labels, encoded_labels_valid)}\n","label_mapping"]},{"cell_type":"markdown","metadata":{},"source":["# Importing the RoBERTa Model"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T06:39:45.931631Z","iopub.status.busy":"2023-08-23T06:39:45.930966Z","iopub.status.idle":"2023-08-23T06:39:50.509232Z","shell.execute_reply":"2023-08-23T06:39:50.508285Z","shell.execute_reply.started":"2023-08-23T06:39:45.931594Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0a5b68b3d384930966a96aad8c1fd6c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0faaa59ca2cb46be8d362a3192f13500","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbf6def287d741febba8eba41ca65811","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa936204c9ca4c0e909507de3170712d","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Import the necessary classes from the transformers library\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","\n","# Initialize a tokenizer using the 'roberta-base' pre-trained model\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","# Initialize a model for sequence classification using the 'roberta-base' pre-trained weights\n","# Set the number of labels to 3\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T08:20:54.027304Z","iopub.status.busy":"2023-08-23T08:20:54.026876Z","iopub.status.idle":"2023-08-23T08:20:54.039089Z","shell.execute_reply":"2023-08-23T08:20:54.037764Z","shell.execute_reply.started":"2023-08-23T08:20:54.027270Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","# Define a custom Dataset class for sentiment classification\n","class Sentiment(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=128):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts[idx])\n","        label = self.labels[idx]\n","        \n","        # Tokenize and encode the text using the provided tokenizer\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","        \n","        # Return a dictionary containing tokenized data and label\n","        return {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","# Use the encoded labels \n","train_labels = encoded_labels_train\n","val_labels = encoded_labels_valid\n","\n","# Create Sentiment instances for training and validation data\n","train_data = Sentiment(train_texts, train_labels, tokenizer, max_len=128)\n","val_data = Sentiment(val_texts, val_labels, tokenizer, max_len=128)\n","\n","# Create DataLoader instances for training and validation data\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=32)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T08:20:56.242895Z","iopub.status.busy":"2023-08-23T08:20:56.242543Z","iopub.status.idle":"2023-08-23T08:20:56.253771Z","shell.execute_reply":"2023-08-23T08:20:56.252404Z","shell.execute_reply.started":"2023-08-23T08:20:56.242865Z"},"trusted":true},"outputs":[],"source":["# Import the AdamW optimizer class from the transformers library\n","from transformers import AdamW\n","\n","# Initialize the AdamW optimizer with the parameters of the model\n","# Set the learning rate (lr) to 1e-5\n","optimizer = AdamW(model.parameters(), lr=1e-5)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T09:10:09.377410Z","iopub.status.busy":"2023-08-23T09:10:09.377032Z","iopub.status.idle":"2023-08-23T09:10:09.384565Z","shell.execute_reply":"2023-08-23T09:10:09.383589Z","shell.execute_reply.started":"2023-08-23T09:10:09.377379Z"},"trusted":true},"outputs":[],"source":["import torch\n","from sklearn.metrics import accuracy_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","import torch\n","from sklearn.metrics import accuracy_score\n","\n","# Check if CUDA (GPU) is available, and move the model to the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Loop over training epochs (here, only 1 epoch as training time is too long for a single epoch)\n","for epoch in range(1):\n","    model.train()  # Set the model to training mode\n","    for batch in train_loader:\n","        optimizer.zero_grad()  # Clear gradients\n","        input_ids = batch['input_ids'].to(device)  # Move input to the device\n","        attention_mask = batch['attention_mask'].to(device)  # Move attention mask to the device\n","        labels = batch['labels'].to(device)  # Move labels to the device\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)  # Forward pass\n","        loss = outputs[0]  # Get the loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update model parameters using gradients\n","\n","    print('I am here')  # Print a message to indicate completion of an epoch\n","    \n","    # Validation loop\n","    model.eval()  # Set the model to evaluation mode\n","    val_loss = 0\n","    val_accuracy = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs[0]\n","            val_loss += loss.item()\n","\n","            # Calculate accuracy\n","            logits = outputs.logits\n","            predictions = torch.argmax(logits, dim=1)\n","            accuracy = accuracy_score(labels.cpu(), predictions.cpu())\n","            val_accuracy += accuracy\n","\n","    val_loss /= len(val_loader)  # Calculate average validation loss\n","    val_accuracy /= len(val_loader)  # Calculate average validation accuracy\n","    print(f'Validation Loss: {val_loss}')"]},{"cell_type":"markdown","metadata":{},"source":["Validation Loss: 0.08897072631558194  \n","Validation Accuracy: 0.9727128993566677"]},{"cell_type":"markdown","metadata":{},"source":["# Importing Test data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T19:53:11.301798Z","iopub.status.busy":"2023-08-29T19:53:11.301434Z","iopub.status.idle":"2023-08-29T19:53:11.545507Z","shell.execute_reply":"2023-08-29T19:53:11.544573Z","shell.execute_reply.started":"2023-08-29T19:53:11.301768Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_text</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>family mormon have never tried explain them t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>buddhism has very much lot compatible with chr...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>seriously don say thing first all they won get...</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what you have learned yours and only yours wha...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>for your own benefit you may want read living ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>36794</th>\n","      <td>jesus</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>36795</th>\n","      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>36796</th>\n","      <td>downvote karna tha par upvote hogaya</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>36797</th>\n","      <td>haha nice</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>36798</th>\n","      <td>facebook itself now working bjp’ cell</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>36799 rows × 2 columns</p>\n","</div>"],"text/plain":["                                              clean_text  category\n","0       family mormon have never tried explain them t...         1\n","1      buddhism has very much lot compatible with chr...         1\n","2      seriously don say thing first all they won get...        -1\n","3      what you have learned yours and only yours wha...         0\n","4      for your own benefit you may want read living ...         1\n","...                                                  ...       ...\n","36794                                              jesus         0\n","36795  kya bhai pure saal chutiya banaya modi aur jab...         1\n","36796              downvote karna tha par upvote hogaya          0\n","36797                                         haha nice          1\n","36798             facebook itself now working bjp’ cell          0\n","\n","[36799 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Load the dataset from the specified path\n","reddit = pd.read_csv('/kaggle/input/twitter-and-reddit-sentimental-analysis-dataset/Reddit_Data.csv')\n","\n","# Rename the 'clean_comment' column to 'clean_text'\n","reddit.rename(columns={'clean_comment': 'clean_text'}, inplace=True)\n","\n","# Drop rows with missing values (NaN) from the dataset\n","reddit.dropna(inplace=True)\n","\n","# Drop duplicate rows based on the 'clean_text' column\n","reddit.drop_duplicates(subset=['clean_text'], inplace=True)\n","\n","# Reset the index after dropping rows\n","reddit.reset_index(drop=True, inplace=True)\n","\n","# Print the cleaned test data\n","reddit"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T09:29:54.699449Z","iopub.status.busy":"2023-08-23T09:29:54.698727Z","iopub.status.idle":"2023-08-23T09:29:54.708599Z","shell.execute_reply":"2023-08-23T09:29:54.707313Z","shell.execute_reply.started":"2023-08-23T09:29:54.699409Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# Transform the labels of the test data using the label encoder\n","test_enc_labels = label_encoder.transform(reddit['category'])\n","\n","# Create a test dataset using the Sentiment class we defined earlier\n","test_dataset = Sentiment(reddit['clean_text'], test_enc_labels, tokenizer, max_len=128)\n","\n","# Create a DataLoader for the test dataset\n","# DataLoader helps manage batches and shuffling of data during testing\n","test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T09:29:57.339837Z","iopub.status.busy":"2023-08-23T09:29:57.339356Z","iopub.status.idle":"2023-08-23T09:34:23.390821Z","shell.execute_reply":"2023-08-23T09:34:23.389724Z","shell.execute_reply.started":"2023-08-23T09:29:57.339798Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["model.eval()  # Set the model to evaluation mode\n","\n","# Lists to store predicted and true labels\n","all_predictions = []\n","all_true_labels = []\n","\n","# Disable gradient calculation for inference\n","with torch.no_grad():\n","    for batch in test_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # Perform forward pass\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        predictions = torch.argmax(outputs.logits, dim=1)\n","\n","        # Extend the lists with predicted and true labels\n","        all_predictions.extend(predictions.cpu().numpy())\n","        all_true_labels.extend(labels.cpu().numpy())\n","\n","# Convert encoded predictions back to original labels using the label encoder\n","predicted_labels = label_encoder.inverse_transform(all_predictions)\n","true_labels = label_encoder.inverse_transform(all_true_labels)"]},{"cell_type":"markdown","metadata":{},"source":["## Test Results"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T09:34:55.372111Z","iopub.status.busy":"2023-08-23T09:34:55.371708Z","iopub.status.idle":"2023-08-23T09:34:55.461003Z","shell.execute_reply":"2023-08-23T09:34:55.459820Z","shell.execute_reply.started":"2023-08-23T09:34:55.372075Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9576618929862225\n","              precision    recall  f1-score   support\n","\n","        -1.0       0.92      0.92      0.92      8250\n","         0.0       0.98      0.97      0.98     12778\n","         1.0       0.95      0.96      0.96     15771\n","\n","    accuracy                           0.96     36799\n","   macro avg       0.95      0.95      0.95     36799\n","weighted avg       0.96      0.96      0.96     36799\n","\n"]}],"source":["from sklearn.metrics import accuracy_score, classification_report\n","\n","# Calculate accuracy using true_labels and predicted_labels\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","print(f'Accuracy: {accuracy}')\n","\n","# Generate a classification report using true_labels and predicted_labels\n","report = classification_report(true_labels, predicted_labels)\n","print(report)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T09:36:56.963858Z","iopub.status.busy":"2023-08-23T09:36:56.963489Z","iopub.status.idle":"2023-08-23T09:36:57.707829Z","shell.execute_reply":"2023-08-23T09:36:57.706808Z","shell.execute_reply.started":"2023-08-23T09:36:56.963826Z"},"trusted":true},"outputs":[],"source":["# Save the state dictionary of the model to the specified file\n","torch.save(model.state_dict(), 'Pre-trained-Sentiment.pth')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
